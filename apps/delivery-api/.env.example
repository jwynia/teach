# Delivery API Environment Configuration
# =======================================
# Copy this file to .env and fill in your values

# Server
PORT=4001

# Database
# SQLite database path for learner progress
APP_DATABASE_URL=file:./data/delivery.db

# LLM Provider Configuration
# ==========================
# These settings configure the AI models used by agents (teaching-agent, coaching-agent)

# Provider: anthropic | openai | openrouter | custom
LLM_PROVIDER=anthropic

# Model name
# - For Anthropic: claude-3-5-sonnet, claude-3-opus-20240229, etc.
# - For OpenAI: gpt-4o, gpt-4o-mini, etc.
# - For OpenRouter: anthropic/claude-3.5-sonnet, openai/gpt-4o, etc.
# - For custom: whatever your endpoint expects
LLM_MODEL=claude-3-5-sonnet

# API key for the selected provider
LLM_API_KEY=your-api-key-here

# Optional: Custom base URL
# - Required for openrouter and custom providers
# - For OpenRouter: https://openrouter.ai/api/v1
# - For self-hosted: https://your-server.com/v1
# LLM_BASE_URL=

# Optional: Additional headers as JSON
# - Useful for OpenRouter (HTTP-Referer, X-Title)
# - Or custom authentication schemes
# LLM_HEADERS={"HTTP-Referer":"https://your-app.com"}

# Example Configurations
# ======================
#
# Anthropic Direct:
#   LLM_PROVIDER=anthropic
#   LLM_MODEL=claude-3-5-sonnet
#   LLM_API_KEY=sk-ant-...
#
# OpenRouter:
#   LLM_PROVIDER=openrouter
#   LLM_MODEL=anthropic/claude-3.5-sonnet
#   LLM_API_KEY=sk-or-...
#   LLM_BASE_URL=https://openrouter.ai/api/v1
#   LLM_HEADERS={"HTTP-Referer":"https://teach.example.com"}
#
# OpenAI:
#   LLM_PROVIDER=openai
#   LLM_MODEL=gpt-4o
#   LLM_API_KEY=sk-...
#
# Self-hosted (Ollama, LMStudio, vLLM, etc.):
#   LLM_PROVIDER=custom
#   LLM_MODEL=llama-3.1-70b
#   LLM_API_KEY=not-needed-but-required
#   LLM_BASE_URL=http://localhost:11434/v1
