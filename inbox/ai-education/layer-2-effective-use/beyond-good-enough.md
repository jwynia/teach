# Beyond Good Enough: Iteration Patterns That Actually Improve AI Output

You've got AI output in front of you. It's... fine. Adequate. The kind of work that technically meets the requirement but doesn't excite anyone.

Most people stop here. Either they accept it, or they say "make it better" and get back something marginally different but still generic.

There's a better way to iterate. This article covers the patterns that actually push AI output from adequate to good.

## The Problem with "Make It Better"

When you say "make it better," AI doesn't know what dimension to improve on. It might:
- Make it longer (more detail = better?)
- Add adjectives (more descriptive = better?)
- Restructure it (different = better?)
- Make it more formal (professional = better?)

You end up with different mediocre instead of better mediocre.

Effective iteration requires direction.

## Pattern 1: The Specificity Push

**When to use:** Output is generic, could apply to anyone/anything.

**The move:** Identify what's generic and demand specifics.

**Instead of:** "Make this more specific"

**Try:**
- "This sounds like it could be for any [product/company/situation]. What makes ours different?"
- "Where in this is there anything someone couldn't guess without knowing our situation?"
- "Replace every adjective with a specific fact or example."

**Example:**
- Generic: "Our innovative platform delivers exceptional results."
- Push: "What specifically is innovative? What results, measured how?"
- Better: "Our platform reduced response time from 3 days to 4 hours for 200+ support teams."

### The "Screenshot Test"

Ask: "If I showed this to someone with no context, would they know it's about [our specific thing]?"

If not, it's too generic. Push for specifics that only apply to your situation.

## Pattern 2: The Surprise Check

**When to use:** Output is predictable, says what everyone expects.

**The move:** Ask what's unexpected or non-obvious.

**Try:**
- "What's the most surprising thing you could say about this topic?"
- "What would make someone pause while reading this?"
- "What's the non-obvious angle?"
- "What do most [emails/articles/docs] like this get wrong?"

**Example:**
- Predictable: "AI can help you work faster and be more productive."
- Push: "What about AI surprises people or contradicts their expectations?"
- Better: "AI often makes work slower at first. The productivity gains come after you learn what it's actually good at—and what to stop asking it for."

### The "They Already Know" Filter

Before including any point, ask: "Would the reader already assume this?"

If yes, either cut it or find the surprising angle within it.

## Pattern 3: The Stakes Raise

**When to use:** Output is accurate but flat, doesn't motivate action.

**The move:** Amplify consequences and implications.

**Try:**
- "What happens if someone ignores this?"
- "What's the cost of getting this wrong?"
- "Why should someone care about this more than everything else competing for their attention?"
- "What's at stake?"

**Example:**
- Flat: "Good documentation helps teams work more efficiently."
- Push: "What happens when documentation is bad?"
- Better: "Bad documentation means your best people spend time answering questions instead of doing work. It's an invisible tax on every team member's day."

### The "So What?" Test

After every major point, ask "So what?" Keep asking until you hit something that matters.

## Pattern 4: The Voice Check

**When to use:** Output sounds like AI (formal, corporate, generic phrasing).

**The move:** Demand human-sounding language.

**Try:**
- "Rewrite this as if you're explaining it to a smart colleague over coffee."
- "Remove any phrase you wouldn't say out loud."
- "Cut every word that's there to sound professional rather than communicate."
- "Write this like a person who cares about the reader, not like someone trying not to get in trouble."

**Example:**
- AI voice: "It is important to leverage synergies across organizational boundaries to facilitate optimal outcomes."
- Push: "Say this like a human talking to another human."
- Better: "Teams work better when they actually talk to each other. Sounds obvious, but most companies make it hard."

### The "Out Loud" Test

Read it aloud. Every phrase that makes you wince or stumble—cut or rewrite.

## Pattern 5: The Constraint Force

**When to use:** Output is stuck in an obvious direction, needs creative escape.

**The move:** Add constraints that make the default impossible.

**Try:**
- "Rewrite without using [obvious word/phrase]."
- "What would this look like if you had to make it half as long?"
- "How would you communicate this if you couldn't use any industry jargon?"
- "What if the first sentence had to be a question?"

**Example:**
- Stuck: "Our team is passionate about delivering innovative solutions."
- Constraint: "Rewrite without 'passionate,' 'innovative,' or 'solutions.'"
- Better: "Our team has shipped 47 features in the last year. Twelve of them came from customer suggestions."

Constraints are creative liberation. When the obvious path is blocked, AI finds better paths.

## Pattern 6: The Comparison Frame

**When to use:** Need to understand what "good" looks like for iteration.

**The move:** Compare current output to excellent examples.

**Try:**
- "Here's a [document] I think is excellent. What does mine lack compared to this?"
- "What would [respected source/person] do differently?"
- "Rate this 1-10 on [specific quality]. What would make it a 10?"

**Example:**
- You: "Here's a product announcement I admire from [Company]. Compare mine to it."
- AI: "Their announcement leads with customer impact. Yours leads with feature description. They use specific numbers. Yours uses vague claims..."

Now you have specific gaps to close.

## Pattern 7: The Reader Simulation

**When to use:** Unsure if output will land with audience.

**The move:** Have AI simulate reader reactions.

**Try:**
- "Read this as a skeptical [target reader]. What would they question or doubt?"
- "What would make [target reader] stop reading?"
- "What questions would [target reader] have after reading this?"
- "What's the most likely objection?"

**Example:**
- You: "Read this as a busy executive who sees 50 emails a day."
- AI: "They'd wonder 'why is this email so long?' The ask is buried in paragraph 4. The subject line is vague..."

Now iterate to address what the simulated reader surfaced.

## Knowing When to Stop

Not every output needs intensive iteration. Consider:

**Iterate hard when:**
- The output will be seen by many people
- It represents you or your organization
- It needs to persuade or motivate
- Getting it wrong has consequences

**Accept "good enough" when:**
- It's for internal/informal use
- Time matters more than polish
- It's one of many similar items
- You'll revise it again anyway

The goal isn't perfection—it's appropriate quality for the context.

## The Iteration Mindset

Effective iteration starts with accepting that first-draft AI output is a starting point, not an ending point.

The model gave you the statistical average. Your job is to:
1. Recognize the specific ways it's average
2. Choose which dimension matters most
3. Push with direction (not "make better" but "make more specific")
4. Recognize when you've reached appropriate quality

AI doesn't know what "better" means for your situation. You do. That's your value in the collaboration.

## Try This

Take an AI output you've accepted recently. Run it through this checklist:

1. **Specificity:** Could this apply to anyone? Push for your specifics.
2. **Surprise:** Is this predictable? Find the unexpected angle.
3. **Stakes:** Does this feel important? Raise the consequences.
4. **Voice:** Does this sound human? Remove corporate filler.
5. **Constraints:** Is this stuck? Force it to avoid the obvious.

Pick the one that addresses the biggest weakness. Iterate on that dimension.

Notice how much better "improve [specific thing]" works compared to "make it better."

---

**Related:**
- [Why AI Gives Mediocre Results](why-ai-gives-mediocre-results.md) - Why first-draft output is average
- [Framework-First Prompting](framework-first-prompting.md) - Getting criteria before you generate
- [Multi-Step Work with AI](multi-step-work.md) - Separating phases for better quality
